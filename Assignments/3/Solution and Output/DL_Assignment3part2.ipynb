{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment3part2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A8VyiRxAcFD",
        "colab_type": "text"
      },
      "source": [
        "# Mounting the google drive with audio files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDoqrYQ0sI9S",
        "colab_type": "code",
        "outputId": "8e8c76ff-cd4f-475d-d4f7-676c8f32594d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-a0AyO9AmIo",
        "colab_type": "text"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scZBQZcGra2P",
        "colab_type": "code",
        "outputId": "d8d67db2-fd26-4ae7-dc04-1e2e2193503c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTcbEMFKAk6a",
        "colab_type": "text"
      },
      "source": [
        "# Function to read data from pickle if exists else from audio files to dump into pickle and read it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m953VBTqGIsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loaddata(pkl , abs_pkl , input):\n",
        "  if os.path.exists(pkl) and os.path.exists(abs_pkl):\n",
        "    s_l = pickle.load(open(pkl, 'rb' ))\n",
        "    abs_s_l = pickle.load(open(abs_pkl, 'rb' ))\n",
        "    print('Loading the data from the pickle')\n",
        "    \n",
        "    return s_l , abs_s_l\n",
        "  \n",
        "  else:\n",
        "    s_l = []\n",
        "    abs_s_l = []\n",
        "    for file in sorted(glob.iglob(input)):\n",
        "      s,sr = librosa.load(file , sr=None)\n",
        "      S = librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "      s_l.append(S)\n",
        "\n",
        "      abs_S = np.abs(S)\n",
        "      abs_s_l.append(abs_S)\n",
        "\n",
        "    pickle.dump(s_l, open(pkl, 'wb'))\n",
        "    pickle.dump(abs_s_l, open(abs_pkl, 'wb'))\n",
        "    \n",
        "    print('Loading the data from input files to pickle')\n",
        "    return s_l , abs_s_l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7LWrex4MJLX",
        "colab_type": "code",
        "outputId": "89848d06-c2a4-43ae-d189-0cf9379f885f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "import os\n",
        "os.listdir('/content/gdrive/My Drive/Colab Notebooks/data/timit-homework')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cln_s.pkl',\n",
              " 'abs_cln_s.pkl',\n",
              " 'nse_s.pkl',\n",
              " 'abs_nse_s.pkl',\n",
              " 'mix_sp.pkl',\n",
              " 'abs_mix_s.pkl',\n",
              " 'v',\n",
              " 'te',\n",
              " 'val_mix_s.pkl',\n",
              " 'val_abs_mix_s.pkl',\n",
              " 't_s.pkl',\n",
              " 't_abs_s.pkl',\n",
              " 'val_cln_s.pkl',\n",
              " 'val_abs_cln_s.pkl',\n",
              " 'val_nse_s.pkl',\n",
              " 'val_abs_nse_s.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6jv-KBKP3y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.rename('/content/gdrive/My Drive/Colab Notebooks/data/timit-homework/abs_cln_s (1).pkl','/content/gdrive/My Drive/Colab Notebooks/data/timit-homework/abs_cln_s.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkq-2gfZPn0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.rename('/content/gdrive/My Drive/Colab Notebooks/data/timit-homework/cln_s (1).pkl','/content/gdrive/My Drive/Colab Notebooks/data/timit-homework/cln_s.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wcyw-ZUCBfa5",
        "colab_type": "text"
      },
      "source": [
        "# Reading values of clean, noise and mixed audios and appending it to list\n",
        "\n",
        "Checking the length of the appended list to see if the data is correctly read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-H7ihQeHS4n",
        "colab_type": "code",
        "outputId": "56b4190c-d934-46c9-8731-d2c36aac468a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dir = 'gdrive/My Drive/Colab Notebooks/data/timit-homework/'\n",
        "cln_s_pkl = dir + 'cln_s.pkl'\n",
        "abs_cln_s_pkl = dir + 'abs_cln_s.pkl'\n",
        "cln_s_p = dir + 'tr/trs*.wav'\n",
        "\n",
        "cln_s_l, abs_cln_s_l = loaddata(cln_s_pkl, abs_cln_s_pkl, cln_s_p)\n",
        "len(cln_s_l), len(abs_cln_s_l)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the data from the pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 1200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1KlpoJCHTB7",
        "colab_type": "code",
        "outputId": "eee2d12f-5311-4ae5-d362-a8c3e569c133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "nse_s_pkl = dir + 'nse_s.pkl'\n",
        "abs_nse_s_pkl = dir + 'abs_nse_s.pkl'\n",
        "nse_s_p = dir + 'tr/trn*.wav'\n",
        "\n",
        "nse_s_l, abs_nse_s_l = loaddata(nse_s_pkl, abs_nse_s_pkl, nse_s_p)\n",
        "len(nse_s_l), len(abs_nse_s_l)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the data from the pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 1200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzJS7Ue5HTJ8",
        "colab_type": "code",
        "outputId": "39ba3a1d-5e9f-4154-9666-bdb191443104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "mix_s_pkl = dir + 'mix_sp.pkl'\n",
        "abs_mix_s_pkl = dir + 'abs_mix_s.pkl'\n",
        "mix_s_p = dir + 'tr/trx*.wav'\n",
        "\n",
        "mix_s_l, abs_mix_s_l = loaddata(mix_s_pkl, abs_mix_s_pkl, mix_s_p)\n",
        "len(mix_s_l), len(abs_mix_s_l)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the data from the pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 1200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgnbEtemHlag",
        "colab_type": "code",
        "outputId": "dbac8ed7-75c8-46f4-b42e-9f4b06aef32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "val_cln_s_pkl = dir + 'val_cln_s.pkl'\n",
        "val_abs_cln_s_pkl = dir + 'val_abs_cln_s.pkl'\n",
        "val_cln_s_p = dir + 'v/vs*.wav'\n",
        "\n",
        "val_cln_s_l, val_abs_cln_s_l = loaddata(val_cln_s_pkl, val_abs_cln_s_pkl, val_cln_s_p)\n",
        "len(val_cln_s_l), len(val_abs_cln_s_l)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the data from the pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 1200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTNzVEQHHljP",
        "colab_type": "code",
        "outputId": "1ace7b1b-670a-4e85-ca47-365bcd085556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "val_nse_s_pkl = dir + 'val_nse_s.pkl'\n",
        "val_abs_nse_s_pkl = dir + 'val_abs_nse_s.pkl'\n",
        "val_nse_s_p = dir + 'v/vn*.wav'\n",
        "\n",
        "val_nse_s_l, val_abs_nse_s_l = loaddata(val_nse_s_pkl, val_abs_nse_s_pkl, val_nse_s_p)\n",
        "len(val_nse_s_l), len(val_abs_nse_s_l)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the data from the pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 1200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TiWjll8Hlro",
        "colab_type": "code",
        "outputId": "66e24a5a-13fc-4261-c54a-f7fa2562ae89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "val_mix_s_pkl = dir + 'val_mix_s.pkl'\n",
        "val_abs_mix_s_pkl = dir + 'val_abs_mix_s.pkl'\n",
        "val_mix_s_p = dir + 'v/vx*.wav'\n",
        "\n",
        "val_mix_s_l, val_abs_mix_s_l = loaddata(val_mix_s_pkl, val_abs_mix_s_pkl, val_mix_s_p)\n",
        "len(val_mix_s_l), len(val_abs_mix_s_l)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the data from the pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 1200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv_Sf89fHtnp",
        "colab_type": "code",
        "outputId": "2fc5d3af-fe25-4d19-df16-6b53ded69825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "t_s_pkl = dir + 't_s.pkl'\n",
        "t_abs_s_pkl = dir + 't_abs_s.pkl'\n",
        "t_s_p = dir + 'te/tex*.wav'\n",
        "\n",
        "t_s_l, t_abs_s_l = loaddata(t_s_pkl, t_abs_s_pkl, t_s_p)\n",
        "len(t_s_l), len(t_abs_s_l) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the data from the pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTkoUIS9g38w",
        "colab_type": "text"
      },
      "source": [
        "# Function for the mask\n",
        "We are converting the variable length to fixed length by taking the longest of the two sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36vpgHJxz4X5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ibm(cln_s , nse_s):\n",
        "\n",
        "  mask = np.greater(cln_s , nse_s) * 1\n",
        "  \n",
        "  return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPlprorURwkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in range(0 , len(abs_cln_s_l)):\n",
        " # print(abs_cln_s_l[i].shape,abs_nse_s_l[i].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arXFgq5I1998",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_l = []\n",
        "\n",
        "for i in range(0 , len(abs_cln_s_l)):\n",
        "  #print(abs_cln_s_l[i].shape,abs_nse_s_l[i].shape)\n",
        "  mask = ibm(abs_cln_s_l[i].T , abs_nse_s_l[i].T)\n",
        "  \n",
        "  mask_l.append(mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t3IP0CaSXqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mask_l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wtxpxibi_Yk",
        "colab_type": "text"
      },
      "source": [
        "# Leaning rate,epochs and batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpSmen362BfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.003\n",
        "n_epochs = 60\n",
        "batch_size = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIOFuJtY2Bk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32, [None, None , 513])\n",
        "y = tf.placeholder(tf.float32, [None, None , 513])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTFMR6w9HIe1",
        "colab_type": "text"
      },
      "source": [
        "# Function for lstm cell\n",
        "\n",
        " I have used he initializer and sigmoid activation function for the lstm model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMml1F-42Bom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm(x , hidden_units):\n",
        "  #LSTM\n",
        "  lstm_cell = tf.contrib.rnn.LSTMCell(hidden_units, initializer=tf.contrib.layers.variance_scaling_initializer())\n",
        "  dropout_lstm = tf.nn.rnn_cell.DropoutWrapper(lstm_cell , output_keep_prob=0.9)\n",
        "  lstm_output , state = tf.nn.dynamic_rnn(dropout_lstm , x , dtype=tf.float32)\n",
        "\n",
        "  output = tf.layers.dense(lstm_output , 513 , activation=tf.nn.sigmoid , kernel_initializer=tf.contrib.layers.variance_scaling_initializer())\n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SyuGqFxHYot",
        "colab_type": "text"
      },
      "source": [
        "# Loss, Optimizer and Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzAb2Uys2Bje",
        "colab_type": "code",
        "outputId": "ec63e550-d8d9-4e7e-aa9f-03d87c8cdd8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "\n",
        "output = lstm(X,  513)\n",
        "loss = tf.losses.mean_squared_error(labels = y ,predictions = output)\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-21-9a200f1d40a7>:3: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-21-9a200f1d40a7>:5: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-21-9a200f1d40a7>:7: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ieNQcRpLFPV",
        "colab_type": "text"
      },
      "source": [
        "# Calculating loss and sum loss for each epoch and appending it in a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlca2fJ-1t4h",
        "colab_type": "code",
        "outputId": "aabc1b0a-143e-4eec-ce1a-628c02c1a39e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loss_l = []\n",
        "sum_loss_l = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    loss_l = []\n",
        "    for i in range(0 , 1200, batch_size):\n",
        "          batch_x = [abs_mix_s_l[j].T for j in range(i,i+batch_size)]\n",
        "          batch_x = np.array(batch_x)\n",
        "          \n",
        "          batch_y = np.array(mask_l[i:i+batch_size])\n",
        "          \n",
        "          batch_x = batch_x.reshape(batch_size,-1,513)\n",
        "          batch_y = batch_y.reshape(batch_size,-1,513)\n",
        "        \n",
        "          feed_dict = {X: batch_x, y: batch_y}\n",
        "          train_step.run(feed_dict=feed_dict)\n",
        "\n",
        "          loss1 = loss.eval(feed_dict=feed_dict)\n",
        "          loss_l.append(loss1)\n",
        "    \n",
        "    sum_loss_l.append(sum(loss_l))\n",
        "    print(\"Epoch:\",epoch, \" loss:\",sum(loss_l))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0  loss: 24.459532618522644\n",
            "Epoch: 1  loss: 20.175379991531372\n",
            "Epoch: 2  loss: 18.533134669065475\n",
            "Epoch: 3  loss: 17.85220941901207\n",
            "Epoch: 4  loss: 17.123674362897873\n",
            "Epoch: 5  loss: 16.612551115453243\n",
            "Epoch: 6  loss: 16.234995365142822\n",
            "Epoch: 7  loss: 15.884008184075356\n",
            "Epoch: 8  loss: 15.61950547248125\n",
            "Epoch: 9  loss: 15.32732992619276\n",
            "Epoch: 10  loss: 15.019042037427425\n",
            "Epoch: 11  loss: 14.756883069872856\n",
            "Epoch: 12  loss: 14.632919698953629\n",
            "Epoch: 13  loss: 14.400542326271534\n",
            "Epoch: 14  loss: 14.175693146884441\n",
            "Epoch: 15  loss: 13.973121732473373\n",
            "Epoch: 16  loss: 13.850290581583977\n",
            "Epoch: 17  loss: 13.727804705500603\n",
            "Epoch: 18  loss: 13.623232401907444\n",
            "Epoch: 19  loss: 13.464034527540207\n",
            "Epoch: 20  loss: 13.309731185436249\n",
            "Epoch: 21  loss: 13.149669088423252\n",
            "Epoch: 22  loss: 13.052400708198547\n",
            "Epoch: 23  loss: 12.930848889052868\n",
            "Epoch: 24  loss: 12.877018183469772\n",
            "Epoch: 25  loss: 12.791102916002274\n",
            "Epoch: 26  loss: 12.606779530644417\n",
            "Epoch: 27  loss: 12.477941334247589\n",
            "Epoch: 28  loss: 12.376281552016735\n",
            "Epoch: 29  loss: 12.294958032667637\n",
            "Epoch: 30  loss: 12.172435812652111\n",
            "Epoch: 31  loss: 12.07316818088293\n",
            "Epoch: 32  loss: 12.002906031906605\n",
            "Epoch: 33  loss: 11.934481643140316\n",
            "Epoch: 34  loss: 11.908435307443142\n",
            "Epoch: 35  loss: 11.846571803092957\n",
            "Epoch: 36  loss: 11.7450492978096\n",
            "Epoch: 37  loss: 11.680347472429276\n",
            "Epoch: 38  loss: 11.689934521913528\n",
            "Epoch: 39  loss: 11.5818902105093\n",
            "Epoch: 40  loss: 11.492982544004917\n",
            "Epoch: 41  loss: 11.404910914599895\n",
            "Epoch: 42  loss: 11.414849758148193\n",
            "Epoch: 43  loss: 11.40450132638216\n",
            "Epoch: 44  loss: 11.277521222829819\n",
            "Epoch: 45  loss: 11.18397831171751\n",
            "Epoch: 46  loss: 11.114651635289192\n",
            "Epoch: 47  loss: 11.057617582380772\n",
            "Epoch: 48  loss: 11.030345983803272\n",
            "Epoch: 49  loss: 11.046921506524086\n",
            "Epoch: 50  loss: 11.004579782485962\n",
            "Epoch: 51  loss: 10.959520429372787\n",
            "Epoch: 52  loss: 10.915860466659069\n",
            "Epoch: 53  loss: 10.908282287418842\n",
            "Epoch: 54  loss: 10.90007808059454\n",
            "Epoch: 55  loss: 10.923122808337212\n",
            "Epoch: 56  loss: 10.883386261761189\n",
            "Epoch: 57  loss: 10.810337699949741\n",
            "Epoch: 58  loss: 10.738777317106724\n",
            "Epoch: 59  loss: 10.679450325667858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlgcywXiNoYV",
        "colab_type": "text"
      },
      "source": [
        "# Feed forward function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjZGD4gF2BZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def feed_forward(input, output):\n",
        "    output = output.eval(feed_dict = {X : input})\n",
        "    \n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmedMCyNQbDM",
        "colab_type": "text"
      },
      "source": [
        "# Function to calculate SNR for the denoised audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w60_f9A7Nid2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_SNR(cln_s , rec_s , size):\n",
        "  cln_s = cln_s[: size]\n",
        "  S_cap1 = np.dot(cln_s.T , cln_s)\n",
        "  S_cap2 = np.dot((cln_s - rec_s).T,(cln_s - rec_s))\n",
        "  SNR = 10 * np.log10(S_cap1/S_cap2)\n",
        "\n",
        "  \n",
        "  return SNR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPCl0SSUm1Uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b54e0946-dde7-43c7-f09b-9b179491c568"
      },
      "source": [
        "len(val_abs_mix_s_l),len(val_mix_s_l)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 1200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCAcm8BhQeTK",
        "colab_type": "text"
      },
      "source": [
        "# Calculating SNR for the Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iZt5ei92Wpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SNR = []\n",
        "for i in range(1200):\n",
        "\n",
        "  ff_ip = np.array([val_abs_mix_s_l[i].T])\n",
        "  ff_op = feed_forward(ff_ip , output)\n",
        "\n",
        "  s_clex = np.array([val_mix_s_l[i].T])\n",
        "  shat = np.multiply(ff_op, s_clex)\n",
        "  shat = shat.T[:,:,0]\n",
        "  recon_s = librosa.istft(shat , hop_length=512 , win_length=1024)\n",
        "  \n",
        "  file_n = str(i).zfill(4)\n",
        "  librosa.output.write_wav('val_recon' + file_n + '.wav', recon_s, sr = 16000)\n",
        "  \n",
        "  cln_s = librosa.istft(val_cln_s_l[i] , hop_length=512 , win_length=1024)\n",
        "  \n",
        "  size_recon_s = np.shape(recon_s)[0]\n",
        "  \n",
        "  snr = calculate_SNR(cln_s , recon_s , size_recon_s)\n",
        "  (recon_s[i]).shape\n",
        "  \n",
        "  SNR.append(snr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKDwmHjy2Wwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "16105cd3-c98a-4bd8-be57-61aab84d0630"
      },
      "source": [
        "print('Minimum SNR of 1200 files:',min(SNR))\n",
        "print('Maximum SNR of 1200 files:',max(SNR))\n",
        "print('Mean SNR of 1200 files:',np.mean(SNR))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum SNR of 1200 files: 4.776942133903503\n",
            "Maximum SNR of 1200 files: 27.115120887756348\n",
            "Mean SNR of 1200 files: 11.701403932273388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-Wzom__RVC_",
        "colab_type": "text"
      },
      "source": [
        "# Generating Reconstructed test audios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FocwnC-Q2W46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "for i in range(400):\n",
        "  ff_ip = np.array([t_abs_s_l[i].T])\n",
        "  ff_op = feed_forward(ff_ip , output)\n",
        "\n",
        "  s_clex = np.array([t_s_l[i].T])\n",
        "  shat = np.multiply(ff_op, s_clex)\n",
        "  shat = shat.T[:,:,0]\n",
        "  recon_s = librosa.istft(shat , hop_length=512 , win_length=1024)\n",
        "  \n",
        "  file_n = str(i).zfill(4)\n",
        "  librosa.output.write_wav('test_recon' + file_n + '.wav', recon_s, sr = 16000)\n",
        "  files.download('test_recon' + file_n + '.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}